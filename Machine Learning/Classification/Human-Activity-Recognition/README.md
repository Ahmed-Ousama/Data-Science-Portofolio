# Human-Activity-Recognition
![451302_1_En_5_Fig1_HTML](https://user-images.githubusercontent.com/83561056/159908609-65c5635b-61e2-497f-91b3-ccf1ae7b9acc.gif)


We will be using the Human Activity Recognition with Smartphones database (https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) , which was built from the recordings of study participants performing activities of daily living (ADL) while carrying a smartphone with an embedded inertial sensors.


The objective is to classify activities into one of the six activities (walking, walking upstairs, walking downstairs, sitting, standing, and laying) performed. 
For each record in the dataset it is provided:

-Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.
-Triaxial Angular velocity from the gyroscope.
-A 561-feature vector with time and frequency domain variables.
-Its activity label.


The CSV file is big to uplod it on github so i uploaded it on drive and you can get it from that link:

https://drive.google.com/file/d/1XlgztGRI1eOKlcfXMP7sjiEVaR6JbHMg/view?usp=sharing
